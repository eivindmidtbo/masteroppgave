{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for placing the hashed trajectories into buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root found: c:\\Users\\eivin\\dev\\JoonEndreLSH\\masteroppgave\n"
     ]
    }
   ],
   "source": [
    "# Importing nescessary modules\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import timeit as ti\n",
    "from tqdm import tqdm\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def find_project_root(target_folder=\"masteroppgave\"):\n",
    "    \"\"\"Find the absolute path of a folder by searching upward.\"\"\"\n",
    "    currentdir = os.path.abspath(\"__file__\")  # Get absolute script path\n",
    "    while True:\n",
    "        if os.path.basename(currentdir) == target_folder:\n",
    "            return currentdir  # Found the target folder\n",
    "        parentdir = os.path.dirname(currentdir)\n",
    "        if parentdir == currentdir:  # Stop at filesystem root\n",
    "            return None\n",
    "        currentdir = parentdir  # Move one level up\n",
    "\n",
    "# Example usage\n",
    "project_root = find_project_root(\"masteroppgave\")\n",
    "\n",
    "if project_root:\n",
    "    sys.path.append(project_root)\n",
    "    print(f\"Project root found: {project_root}\")\n",
    "else:\n",
    "    raise RuntimeError(\"Could not find 'masteroppgave' directory\")\n",
    "\n",
    "from utils.helpers.save_trajectory import save_trajectory_hashes\n",
    "from utils.helpers import file_handler as fh\n",
    "from utils.helpers import metafile_handler as mfh\n",
    "from schemes.lsh_disk import DiskLSH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CityHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest Bucket: 284810363214875717150971988534373310147\n",
      "Total Buckets: 4587\n",
      "Buckets with more than one trajectory: 1340\n",
      "Buckets with only one trajectory: 3247\n",
      "Largest Bucket Size: 40\n",
      "Percentage of buckets with more than one trajectory: 29.21%\n",
      "Percentage of buckets with only one trajectory: 70.79%\n"
     ]
    }
   ],
   "source": [
    "import cityhash\n",
    "import os\n",
    "from constants import NUMBER_OF_TRAJECTORIES\n",
    "\n",
    "# Paths\n",
    "ROME_HASHED_TRAJECTORIES_OUTPUT_FOLDER = \"../../dataset/hashed_data/grid/rome/\"\n",
    "ROME_HASHED_TRAJECTORIES_FOLDER_META_FILE = f\"{ROME_HASHED_TRAJECTORIES_OUTPUT_FOLDER}META-{NUMBER_OF_TRAJECTORIES}.txt\"\n",
    "\n",
    "ROME_FULL_TRAJECTORIES_OUTPUT_FOLDER = \"../../dataset/rome/output/\"\n",
    "\n",
    "# Dictionary for the bucket system\n",
    "bucket_system = {}\n",
    "\n",
    "# Get filenames from the metafile\n",
    "files = mfh.read_meta_file(ROME_HASHED_TRAJECTORIES_FOLDER_META_FILE)\n",
    "\n",
    "# Iterate through trajectory files and read their hashes\n",
    "for filename in files:\n",
    "    file_path = os.path.join(ROME_HASHED_TRAJECTORIES_OUTPUT_FOLDER, filename)\n",
    "    \n",
    "    # Read the hashes for the trajectory\n",
    "    trajectory_hashes = fh.read_hash_file(file_path)\n",
    "    \n",
    "    # Iterate over each layer's hash\n",
    "    \n",
    "    for layer_hash in trajectory_hashes:\n",
    "        # Convert the list of coordinates into a string\n",
    "        hash_string = \"_\".join(map(str, layer_hash))\n",
    "        \n",
    "        # Use CityHash for creating a unique key\n",
    "        hash_key = cityhash.CityHash128(hash_string)\n",
    "        \n",
    "        # Place trajectory into the appropriate bucket\n",
    "        if hash_key not in bucket_system:\n",
    "            bucket_system[hash_key] = []\n",
    "        bucket_system[hash_key].append(filename)\n",
    "\n",
    "    \n",
    "# # print the bucket system\n",
    "# for bucket, trajectories in bucket_system.items():\n",
    "#     print(f\"Bucket {bucket}: {trajectories}\")\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "# Analyze and display results\n",
    "\n",
    "total_buckets = len(bucket_system)\n",
    "buckets_with_multiple = sum(1 for trajectories in bucket_system.values() if len(trajectories) > 1)\n",
    "buckets_with_single = total_buckets - buckets_with_multiple\n",
    "largest_bucket_size = max(len(trajectories) for trajectories in bucket_system.values())\n",
    "largest_bucket = max(bucket_system, key=lambda key: len(bucket_system[key]))\n",
    "print(f\"Largest Bucket: {largest_bucket}\")\n",
    "\n",
    "print(f\"Total Buckets: {total_buckets}\")\n",
    "print(f\"Buckets with more than one trajectory: {buckets_with_multiple}\")\n",
    "print(f\"Buckets with only one trajectory: {buckets_with_single}\")\n",
    "print(f\"Largest Bucket Size: {largest_bucket_size}\")\n",
    "\n",
    "# Optional: Display distribution percentages\n",
    "multiple_bucket_percentage = (buckets_with_multiple / total_buckets) * 100 if total_buckets > 0 else 0\n",
    "single_bucket_percentage = (buckets_with_single / total_buckets) * 100 if total_buckets > 0 else 0\n",
    "\n",
    "print(f\"Percentage of buckets with more than one trajectory: {multiple_bucket_percentage:.2f}%\")\n",
    "print(f\"Percentage of buckets with only one trajectory: {single_bucket_percentage:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 44 bytes\n",
      "Memory used: 154 bytes\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "number = 244816790760326619827359513135372348218\n",
    "print(f\"Memory used: {sys.getsizeof(number)} bytes\")\n",
    "\n",
    "key = '41.90297084408296, 12.48512374477741, 41.91382330487844, 12.48512374477741, 41.91382330487844, 12.470645453170416'\n",
    "print(f\"Memory used: {sys.getsizeof(key)} bytes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_repo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
