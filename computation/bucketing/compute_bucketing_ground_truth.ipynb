{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for generating ground truth for bucketing. \n",
    "\n",
    "Takes a dataset and creates a dictionary containing all trajectories from dataset and the corresponding trajectories meeting similarity below threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for checking true similarity between a pair of trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing row R_DVK and column R_CAV\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4753952612424382"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ROME_TRUE_SIMILARITY_FILE = \"../../results_true/similarity_values/rome/dtw/rome-dtw-3050.csv\"\n",
    "\n",
    "def get_true_similarity(filename1: str, filename2: str) -> float | None:\n",
    "    \"\"\"\n",
    "    Find the true similarity between two trajectory filenames using a similarity matrix file.\n",
    "\n",
    "    Args:\n",
    "        filename1 (str): First trajectory file (with or without `.txt`).\n",
    "        filename2 (str): Second trajectory file (with or without `.txt`).\n",
    "\n",
    "    Returns:\n",
    "        float | None: The similarity value if found, otherwise None.\n",
    "    \"\"\"\n",
    "    # Load the similarity matrix CSV\n",
    "    similarity_df = pd.read_csv(ROME_TRUE_SIMILARITY_FILE, index_col=0)\n",
    "    \n",
    "    # Clean file names by removing '.txt'\n",
    "    t1_clean = filename1.replace('.txt', '')\n",
    "    t2_clean = filename2.replace('.txt', '')\n",
    "\n",
    "    # Ensure correct row-column order for the matrix\n",
    "    if t1_clean < t2_clean:\n",
    "        t1_clean, t2_clean = t2_clean, t1_clean\n",
    "\n",
    "    # Check if both are in the DataFrame\n",
    "    if t1_clean in similarity_df.index and t2_clean in similarity_df.columns:\n",
    "        print(f\"Accessing row {t1_clean} and column {t2_clean}\")\n",
    "        return float(similarity_df.loc[t1_clean, t2_clean])\n",
    "    elif t2_clean in similarity_df.index and t1_clean in similarity_df.columns:\n",
    "        print(f\"Accessing row {t2_clean} and column {t1_clean}\")\n",
    "        return float(similarity_df.loc[t2_clean, t1_clean])\n",
    "    else:\n",
    "        print(f\"Missing pair in similarity matrix: {filename1}, {filename2}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "get_true_similarity(\"R_CAV\", \"R_DVK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#City to use (used for filepath)\n",
    "CITY = \"rome\"\n",
    "#Measure to use (used for filepath)\n",
    "MEASURE = \"dtw\"\n",
    "#Number of trajectories (used for filepath, which metafile to use)\n",
    "NUMBER_OF_TRAJECTORIES= 3050\n",
    "#Threshold for similarity value\n",
    "THRESHOLD = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Filepath to dataset containing similarity values\n",
    "file_path = f\"../../results_true/similarity_values/{CITY}/{MEASURE}/{CITY}-{MEASURE}-{NUMBER_OF_TRAJECTORIES}.csv\"\n",
    "\n",
    "# Read CSV, telling pandas to take the first column as the row labels:\n",
    "similarity_df = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "# Function to convert values to float if possible\n",
    "def convert_to_float(value):\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return value\n",
    "\n",
    "# Apply the function to each cell in the DataFrame\n",
    "similarity_df = similarity_df.map(convert_to_float)\n",
    "number_of_trajectories_in_dataframe = similarity_df.shape[1]\n",
    "column_names = similarity_df.columns\n",
    "\n",
    "print(f\"Currently working with true similarity values for {CITY} using {MEASURE} with {NUMBER_OF_TRAJECTORIES} trajectories\")\n",
    "\n",
    "print(f\"Number of trajectories: {number_of_trajectories_in_dataframe}\")\n",
    "# print(f\"Column names: {column_names}\")\n",
    "\n",
    "#Make the dataframe symmetric\n",
    "symmetric_df = (similarity_df + similarity_df.T)\n",
    "# Display the DataFrame\n",
    "symmetric_df.head(40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print single row from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_row = symmetric_df[[\"R_ABU\"]]\n",
    "single_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find lowest similarity value in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the DataFrame to avoid modifying the original\n",
    "df_no_diag = symmetric_df.copy()\n",
    "\n",
    "# Replace diagonal values (self-similarity) with NaN to exclude them\n",
    "np.fill_diagonal(df_no_diag.values, np.nan)\n",
    "\n",
    "# Find the minimum value excluding the diagonal\n",
    "min_value = df_no_diag.min().min()\n",
    "\n",
    "# Find the corresponding row and column (trajectory names)\n",
    "min_location = df_no_diag.stack().idxmin()  # Finds the index location of the minimum value\n",
    "\n",
    "# Print results\n",
    "print(f\"Lowest similarity value (excluding diagonal): {min_value}\")\n",
    "print(f\"Between trajectories: {min_location[0]} and {min_location[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find average similarity between all col x rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to NumPy array\n",
    "\n",
    "avg_df = symmetric_df.copy()\n",
    "\n",
    "similarity_matrix = avg_df.values.astype(float)\n",
    "\n",
    "# Compute the mean including the diagonal (all values)\n",
    "mean_including_diagonal = similarity_matrix.mean()\n",
    "\n",
    "# Compute the mean excluding the diagonal (ignore self-similarity)\n",
    "np.fill_diagonal(similarity_matrix, np.nan)  # Replace diagonal with NaN\n",
    "mean_excluding_diagonal = np.nanmean(similarity_matrix)  # Compute mean excluding NaN values\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean similarity including diagonal: {mean_including_diagonal}\")\n",
    "print(f\"Mean similarity excluding diagonal: {mean_excluding_diagonal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ground truth for trajectories in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = []\n",
    "\n",
    "#Loops over each column of the dataframe. \n",
    "for i in range(number_of_trajectories_in_dataframe):\n",
    "    filtered_column = symmetric_df.iloc[:, i]\n",
    "      \n",
    "    #Filter column rows on treshold value\n",
    "    df_threshold = filtered_column[filtered_column< THRESHOLD]\n",
    "    \n",
    "    series = pd.Series(df_threshold, name=filtered_column.name)  # Assign name for self-reference\n",
    "    \n",
    "    filtered_series = series[series.index != series.name]\n",
    "    \n",
    "    #Convert to dictionary\n",
    "    result_dict = {f\"{filtered_column.name}\": filtered_series.index.tolist()}  # Store index names\n",
    "    \n",
    "    result_df.append(result_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print all lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in result_df:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print one list and corresponding values from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAJECTORY = \"R_ABU\"\n",
    "values = []\n",
    "\n",
    "for item in result_df:\n",
    "    if item.get(TRAJECTORY):\n",
    "        values = item.get(TRAJECTORY)\n",
    "        print(f\"{TRAJECTORY}: {item.get(TRAJECTORY)}\")\n",
    "        break\n",
    "\n",
    "#Print the group with corresponding similarity values\n",
    "filtered_column = symmetric_df[[TRAJECTORY]]\n",
    "filtered_result = filtered_column.loc[values]\n",
    "filtered_result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
