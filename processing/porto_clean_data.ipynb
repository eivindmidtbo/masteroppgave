{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sheet for extracting raw-data from Porto dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from haversine import haversine, Unit\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.append(parentdir)\n",
    "\n",
    "from utils.helpers.metafile_handler import create_meta_files\n",
    "from utils.helpers.save_trajectory import save_current_trajectory\n",
    "from utils.helpers.alphabetical_number import increment_alphabetical\n",
    "from utils.helpers.file_handler import delete_old_files\n",
    "\n",
    "\n",
    "# Helper function to compute distance between a list of coordinates (Trajectory distance)\n",
    "# Haversine distance used\n",
    "def calculate_trajectory_distance(positions: list[tuple[float]]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the trajectory distance for a trajectory\n",
    "\n",
    "    :param: List of coordinates (lat, lon)\n",
    "\n",
    "    :return: Float (km) -> Combined distance between all pairs of points in km\n",
    "    \"\"\"\n",
    "    distance = 0\n",
    "    for i in range(1, len(positions)):\n",
    "        from_location = positions[i - 1]\n",
    "        to_location = positions[i]\n",
    "\n",
    "        distance += haversine(from_location, to_location, unit=Unit.KILOMETERS)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import P_MAX_LAT, P_MAX_LON, P_MIN_LAT, P_MIN_LON, PORTO_OUTPUT_FOLDER\n",
    "# Containning variables and constants for this spreadsheet\n",
    "SHOULD_DELETE_OLD_FILES = True\n",
    "\n",
    "OUTPUT_FOLDER = f\"../{PORTO_OUTPUT_FOLDER}\"\n",
    "RAW_DATA_FILE = \"../dataset/porto/porto_raw.csv\"\n",
    "OUTPUT_DATA_FILE = \"../dataset/porto/porto.csv\"\n",
    "\n",
    "LOG = False  # Set to true for printing during data extraction\n",
    "\n",
    "\n",
    "MIN_LEN = 40\n",
    "\n",
    "NUMBER_OF_TRACES = 3000\n",
    "MAX_DIST_BETWEEN_COORDINATES = 0.2  # Km\n",
    "\n",
    "X = calculate_trajectory_distance([(P_MIN_LAT, P_MIN_LON), (P_MAX_LAT, P_MIN_LON)])\n",
    "Y = calculate_trajectory_distance([(P_MIN_LAT, P_MIN_LON), (P_MIN_LAT, P_MAX_LON)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset into dataframe\n",
    "\n",
    "raw_df = pd.read_csv(RAW_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to clear the chosen files in the PORTO folder\n",
    "\n",
    "if SHOULD_DELETE_OLD_FILES:\n",
    "    delete_old_files(OUTPUT_FOLDER, \"META\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cleaned trajectories written to file: 3000\n"
     ]
    }
   ],
   "source": [
    "# Read the data, clean it and insert to cleaned csv file\n",
    "\n",
    "cleaned_trajectories = []\n",
    "counter = 0\n",
    "name_counter = \"AAA\"\n",
    "\n",
    "for index, row in raw_df.iterrows():\n",
    "    trace_id = row[\"TRIP_ID\"]\n",
    "\n",
    "    # If row is missing data: ignore row\n",
    "    if row[\"MISSING_DATA\"] == True:\n",
    "        if LOG:\n",
    "            print(trace_id, \"is missing data\")\n",
    "        continue\n",
    "    trace = row[\"POLYLINE\"][2:-2].split(\"],[\")\n",
    "\n",
    "    # If trace-length less than \"MIN_LEN\": ignore row\n",
    "    if len(trace) < MIN_LEN:\n",
    "        if LOG:\n",
    "            print(trace_id, \"is less than preferred length\")\n",
    "        continue\n",
    "\n",
    "    # If trace are outside bounded rectangle or noisy data: ignore row\n",
    "\n",
    "    last_coordinate = trace[0]\n",
    "    for coordinate in trace:\n",
    "        lon, lat = list(map(float, coordinate.split(\",\")))\n",
    "\n",
    "        # Outside bounded rectangle\n",
    "        if (not (P_MIN_LAT <= lat <= P_MAX_LAT)) or (not (P_MIN_LON <= lon <= P_MAX_LON)):\n",
    "            if LOG:\n",
    "                print(trace_id, \"is outside bounded rectangle\")\n",
    "            break\n",
    "\n",
    "        # Traces with noisy data:\n",
    "        if last_coordinate != coordinate:\n",
    "            last_lon, last_lat = list(map(float, last_coordinate.split(\",\")))\n",
    "            distance = calculate_trajectory_distance([(last_lat, last_lon), (lat, lon)])\n",
    "\n",
    "            # If distance between two consecutive coordinates are too great:\n",
    "            if distance > MAX_DIST_BETWEEN_COORDINATES:\n",
    "                if LOG:\n",
    "                    print(\"Possibly noisy data - continuing with next trace\")\n",
    "                break\n",
    "\n",
    "        last_coordinate = coordinate\n",
    "        # IMPLEMENT HERE, use distance function\n",
    "\n",
    "    # Else, everything is good so far --> Write trajectory to file\n",
    "    else:\n",
    "        cleaned_trajectories.append(row)\n",
    "        trajectory = []\n",
    "        for coordinate in trace:\n",
    "            lon, lat = list(map(float, coordinate.split(\",\")))\n",
    "            trajectory.append((lat, lon))\n",
    "        save_current_trajectory(\n",
    "            OUTPUT_FOLDER=OUTPUT_FOLDER,\n",
    "            file_name=name_counter,\n",
    "            trajectory=trajectory,\n",
    "            trajectory_file_prefix=\"P\",\n",
    "        )\n",
    "\n",
    "        counter += 1\n",
    "        name_counter = increment_alphabetical(name_counter)\n",
    "\n",
    "        if counter >= NUMBER_OF_TRACES:\n",
    "            break\n",
    "\n",
    "cleaned_df_columns = [\n",
    "    \"TRIP_ID\",\n",
    "    \"CALL_TYPE\",\n",
    "    \"ORIGIN_CALL\",\n",
    "    \"ORIGIN_STAND\",\n",
    "    \"TAXI_ID\",\n",
    "    \"TIMESTAMP\",\n",
    "    \"DAY_TYPE\",\n",
    "    \"MISSING_DATA\",\n",
    "    \"POLYLINE\",\n",
    "]\n",
    "cleaned_df = pd.DataFrame(cleaned_trajectories, columns=cleaned_df_columns)\n",
    "cleaned_df.to_csv(OUTPUT_DATA_FILE, index=False)\n",
    "\n",
    "\n",
    "print(\"Number of cleaned trajectories written to file:\", counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_meta_files(path_to_files=OUTPUT_FOLDER, data_prefix=\"P_\", number=50, create_test_set=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average number of points per trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.04633901705115\n"
     ]
    }
   ],
   "source": [
    "total_lines = 0\n",
    "file_count = 0\n",
    "\n",
    "for root, dirs, files in os.walk(OUTPUT_FOLDER):\n",
    "    for file in files:\n",
    "        try:\n",
    "            with open(os.path.join(root, file), 'r') as f:\n",
    "                total_lines += sum(1 for line in f)\n",
    "                file_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "if file_count > 0:\n",
    "    print(total_lines / file_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6+"
  },
  "vscode": {
   "interpreter": {
    "hash": "6a8cebea5680a70624bfb085291ac11ac025ad85fe214511868677846ba38b53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
